import asyncio
import aiohttp
import json
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import base64

# é…ç½®æ›´è¯¦ç»†çš„æ—¥å¿—
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("WeComTaskProcessor")

# ä¼ä¸šå¾®ä¿¡é…ç½®
CORPID = "wwb0728887ce23a4ce"
CORPSECRET = "vZ7mge0BomfhLaza43spNe9Wb8EmBdjmWQzxrhD10j4"

# æ™ºèƒ½è¡¨APIé…ç½®
API_URL = "https://smallwecom.yesboss.work/smarttable"
HEADERS = {
    "Content-Type": "application/json; charset=utf-8",
    "Accept": "application/json"
}


class WeComTaskHandler:
    """ä¼ä¸šå¾®ä¿¡ä»»åŠ¡å¤„ç†ç±»ï¼ˆå®Œæ•´ç‰ˆï¼‰"""

    def __init__(self, corpid: str, corpsecret: str):
        self.corpid = corpid
        self.corpsecret = corpsecret
        self.access_token = None
        self.token_expires_at = 0
        self.timeout = aiohttp.ClientTimeout(total=60)
        self._session = None  # å»¶è¿Ÿåˆ›å»ºä¼šè¯

    async def _get_session(self):
        """åˆ›å»ºæˆ–è¿”å›ç°æœ‰ä¼šè¯"""
        if self._session is None or self._session.closed:
            self._session = aiohttp.ClientSession()
            logger.debug("âœ… åˆ›å»ºæ–°çš„aiohttpä¼šè¯")
        return self._session

    async def _get_access_token(self) -> Optional[str]:
        """è·å–ä¼ä¸šå¾®ä¿¡è®¿é—®ä»¤ç‰Œï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰"""
        logger.debug("å°è¯•è·å–AccessToken...")
        if self.access_token and self.token_expires_at > datetime.now().timestamp():
            logger.debug("âœ… ä½¿ç”¨ç¼“å­˜çš„AccessToken")
            return self.access_token

        session = await self._get_session()
        token_url = (
            f"https://qyapi.weixin.qq.com/cgi-bin/gettoken"
            f"?corpid={self.corpid}"
            f"&corpsecret={self.corpsecret}"
        )

        logger.debug(f"è¯·æ±‚AccessToken: {token_url}")
        try:
            async with session.get(token_url, timeout=self.timeout) as resp:
                result = await resp.json()
                logger.debug(f"AccessTokenå“åº”: {json.dumps(result)}")
                if result.get("errcode") == 0:
                    self.access_token = result["access_token"]
                    self.token_expires_at = datetime.now().timestamp() + 7100
                    logger.info("âœ… è·å–ä¼å¾®AccessTokenæˆåŠŸ")
                    return self.access_token
                else:
                    error_msg = f"è·å–AccessTokenå¤±è´¥ï¼š{result.get('errmsg')}ï¼ˆé”™è¯¯ç ï¼š{result.get('errcode')}ï¼‰"
                    logger.error(error_msg)
                    return None
        except Exception as e:
            logger.error(f"è·å–AccessTokenå¼‚å¸¸ï¼š{str(e)}")
            return None

    async def upload_temp_media(self, img_data: bytes, file_name: str) -> Optional[str]:
        """ä½¿ç”¨ä¸´æ—¶ç´ ææ¥å£ä¸Šä¼ å›¾ç‰‡ï¼ˆæ— éœ€docidï¼‰"""
        logger.debug(f"ä¸´æ—¶ç´ æä¸Šä¼ : {file_name} (å¤§å°: {len(img_data) // 1024}KB)")
        access_token = await self._get_access_token()
        if not access_token:
            logger.error("âŒ æ— AccessTokenï¼Œç´ æä¸Šä¼ å¤±è´¥")
            return None

        url = f"https://qyapi.weixin.qq.com/cgi-bin/media/upload?access_token={access_token}&type=image"

        try:
            form_data = aiohttp.FormData()
            form_data.add_field('media', img_data, filename=file_name)

            async with self._session.post(url, data=form_data) as resp:
                # å…ˆè·å–æ–‡æœ¬å“åº”é¿å…JSONè§£æé”™è¯¯
                resp_text = await resp.text()
                try:
                    result = json.loads(resp_text)
                except json.JSONDecodeError:
                    logger.error(f"âŒ ç´ ææ¥å£è¿”å›éJSON: {resp_text[:200]}...")
                    return None

                if result.get("errcode") == 0:
                    media_id = result.get("media_id")
                    logger.info(f"âœ… ä¸´æ—¶ç´ æä¸Šä¼ æˆåŠŸ: {file_name} â†’ media_id: {media_id[:20]}...")
                    return media_id
                else:
                    error_msg = result.get("errmsg", "æœªçŸ¥é”™è¯¯")
                    logger.error(f"âŒ ç´ æä¸Šä¼ å¤±è´¥ï¼ˆ{result['errcode']}ï¼‰: {error_msg}")
        except Exception as e:
            logger.error(f"ç´ æä¸Šä¼ å¼‚å¸¸: {str(e)}")
        return None

    async def create_mass_task(
            self,
            external_userid: List[str],
            sender: str,
            content: str,
            task_name: str,
            image_urls: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """åˆ›å»ºç¾¤å‘ä»»åŠ¡ï¼ˆå¸¦å›¾ç‰‡ï¼šä¸‹è½½â†’å‹ç¼©â†’å¾®ç›˜ä¸Šä¼ â†’æ„é€ é™„ä»¶ï¼‰"""
        logger.info(f"ğŸ“¨ åˆ›å»ºç¾¤å‘ä»»åŠ¡: {task_name} (å‘é€äºº: {sender}, æ¥æ”¶äºº: {len(external_userid)}ä¸ª)")
        access_token = await self._get_access_token()
        if not access_token:
            return {"success": False, "error": "æ— æ³•è·å–AccessToken"}

        session = await self._get_session()
        full_content = content
        attachments = []  # å›¾ç‰‡é™„ä»¶åˆ—è¡¨ï¼ˆæœ€ç»ˆè¦ä¼ ç»™ç¾¤å‘æ¥å£ï¼‰

        # ä¿®æ”¹åæ­£ç¡®çš„ä»£ç éƒ¨åˆ†ï¼š
        # ---------------------- æ ¸å¿ƒï¼šå›¾ç‰‡å¤„ç†+ä¸´æ—¶ç´ æä¸Šä¼  ----------------------
        if image_urls:
            logger.info(f"å‡†å¤‡å¤„ç† {len(image_urls)} å¼ å›¾ç‰‡ï¼ˆä¸´æ—¶ç´ æä¸Šä¼ æ¨¡å¼ï¼‰...")
            for img_url in image_urls:
                if not img_url:
                    continue

                try:
                    # 1. ä¸‹è½½å›¾ç‰‡ï¼ˆ300ç§’è¶…æ—¶ï¼‰
                    logger.debug(f"ä¸‹è½½å›¾ç‰‡: {img_url}")
                    img_timeout = aiohttp.ClientTimeout(total=300)
                    async with session.get(img_url, timeout=img_timeout) as resp:
                        if resp.status != 200:
                            logger.error(f"âŒ å›¾ç‰‡ä¸‹è½½å¤±è´¥ï¼ˆçŠ¶æ€ç {resp.status}ï¼‰: {img_url}")
                            continue
                        img_data = await resp.read()
                        file_name = img_url.split("/")[-1] or "temp_image.png"

                    # 2. å‹ç¼©å›¾ç‰‡ï¼ˆå¿…é¡»â‰¤2MBï¼Œé¿å…ä¸Šä¼ å¤±è´¥ï¼‰
                    max_size = 2 * 1024 * 1024  # 2MBé™åˆ¶
                    if len(img_data) > max_size:
                        logger.warning(f"âš ï¸ å›¾ç‰‡è¿‡å¤§({len(img_data) // 1024}KB)ï¼Œå¼€å§‹å‹ç¼©: {file_name}")
                        try:
                            from PIL import Image
                            import io

                            # æ­¥éª¤1ï¼šæŒ‰æ¯”ä¾‹ç¼©æ”¾ï¼ˆæœ€å¤§1000Ã—1000åƒç´ ï¼‰
                            with Image.open(io.BytesIO(img_data)) as img:
                                max_dim = 1000
                                width, height = img.size
                                if width > max_dim or height > max_dim:
                                    ratio = min(max_dim / width, max_dim / height)
                                    new_size = (int(width * ratio), int(height * ratio))
                                    img = img.resize(new_size, Image.Resampling.LANCZOS)
                                    logger.debug(f"ğŸ“ å›¾ç‰‡ç¼©æ”¾: {width}Ã—{height} â†’ {new_size[0]}Ã—{new_size[1]}")

                                # æ­¥éª¤2ï¼šæŒ‰æ ¼å¼å‹ç¼©ï¼ˆPNGç”¨æ— æŸå‹ç¼©ï¼ŒJPEGç”¨è´¨é‡æ§åˆ¶ï¼‰
                                img_byte_arr = io.BytesIO()
                                if img.format == "PNG":
                                    img.save(img_byte_arr, format="PNG", compress_level=9, optimize=True)
                                else:
                                    quality = 80
                                    while True:
                                        img_byte_arr.seek(0)
                                        img.save(img_byte_arr, format="JPEG", quality=quality, optimize=True)
                                        compressed_data = img_byte_arr.getvalue()
                                        if len(compressed_data) <= max_size or quality <= 30:
                                            break
                                        quality -= 5

                                img_data = img_byte_arr.getvalue()
                                logger.debug(
                                    f"âœ… å‹ç¼©å®Œæˆ: {len(img_data) // 1024}KBï¼ˆè´¨é‡{quality if img.format != 'PNG' else 'æ— æŸ'}ï¼‰")
                        except Exception as e:
                            logger.error(f"âŒ å›¾ç‰‡å‹ç¼©å¤±è´¥: {str(e)}ï¼Œè·³è¿‡æ­¤å›¾")
                            continue

                    # 3. ä½¿ç”¨ä¸´æ—¶ç´ ææ¥å£ä¸Šä¼ ï¼ˆæ— éœ€docidï¼‰
                    media_id = await self.upload_temp_media(img_data, file_name)  # å…³é”®ä¿®æ”¹ç‚¹
                    if not media_id:
                        logger.warning(f"âš ï¸ è·³è¿‡å›¾ç‰‡: {file_name}ï¼ˆç´ æä¸Šä¼ å¤±è´¥ï¼‰")
                        continue

                    # 4. æ„é€ ç¾¤å‘å›¾ç‰‡é™„ä»¶ï¼ˆå…³é”®ï¼šç¬¦åˆä¼å¾®ç¾¤å‘æ¥å£æ ¼å¼ï¼‰
                    attachments.append({
                        "msgtype": "image",
                        "image": {"media_id": media_id}
                    })
                    logger.debug(f"âœ… å›¾ç‰‡é™„ä»¶æ·»åŠ æˆåŠŸ: {file_name}ï¼ˆmedia_id: {media_id[:20]}...ï¼‰")

                except Exception as e:
                    logger.error(f"å›¾ç‰‡å¤„ç†å¼‚å¸¸: {str(e)}ï¼ˆURL: {img_url}ï¼‰")
                    continue
        # ---------------------- å›¾ç‰‡å¤„ç†ç»“æŸ ----------------------

        # 5. æ„é€ ç¾¤å‘è¯·æ±‚ä½“ï¼ˆattachmentsä¸ä¸ºç©ºå³å¸¦å›¾ç‰‡ï¼‰
        payload = {
            "chat_type": "single",
            "external_userid": external_userid,
            "sender": sender,
            "text": {"content": full_content},
            "attachments": attachments  # å›¾ç‰‡é™„ä»¶åœ¨è¿™é‡Œï¼
        }
        logger.debug(f"ç¾¤å‘è¯·æ±‚ä½“ï¼ˆå«é™„ä»¶ï¼‰: {json.dumps(payload, ensure_ascii=False)[:500]}...")

        # 6. è°ƒç”¨ç¾¤å‘æ¥å£ï¼ˆä¿®å¤ç¼©è¿›+è§„èŒƒå˜é‡åï¼‰
        try:
            # æ›¿æ¢ä¸­æ–‡å˜é‡åä¸ºè‹±æ–‡ï¼ˆæ›´è§„èŒƒï¼‰
            mass_url = f"https://qyapi.weixin.qq.com/cgi-bin/externalcontact/add_msg_template?access_token={access_token}"
            async with session.post(mass_url, json=payload, timeout=self.timeout) as resp:
                result = await resp.json()
                logger.debug(f"ç¾¤å‘å“åº”: {json.dumps(result)}")
                if result.get("errcode") == 0:
                    logger.info(f"âœ… ç¾¤å‘ä»»åŠ¡åˆ›å»ºæˆåŠŸ: {task_name}ï¼ˆmsgid: {result['msgid']}ï¼‰")
                    return {
                        "success": True,
                        "msgid": result["msgid"],
                        "attachments_count": len(attachments)
                    }
                else:
                    error_msg = result.get("errmsg", "æœªçŸ¥é”™è¯¯")
                    logger.error(f"âŒ ç¾¤å‘ä»»åŠ¡å¤±è´¥: {error_msg}")
                    return {
                        "success": False,
                        "error": error_msg,
                        "errcode": result.get("errcode")
                    }
        # å…³é”®ï¼šexcept ä¸ä¸Šæ–¹ try ç¼©è¿›ä¸€è‡´ï¼
        except Exception as e:
            logger.error(f"ç¾¤å‘è¯·æ±‚å¼‚å¸¸: {str(e)}")
            return {
                "success": False,
                "error": str(e)
            }


    async def close(self):
        """å…³é—­ä¼šè¯ï¼Œé‡Šæ”¾èµ„æº"""
        if self._session and not self._session.closed:
            await self._session.close()
            logger.info("âœ… å·²å…³é—­ä¼ä¸šå¾®ä¿¡ä¼šè¯")
            self._session = None


async def fetch_task_table(docid: str, sheet_id: str, view_id: str) -> List[Dict]:
    """ä»æ™ºèƒ½è¡¨æŸ¥è¯¢ä»»åŠ¡æ•°æ®"""
    logger.debug(f"æŸ¥è¯¢ä»»åŠ¡è¡¨: docid={docid}, sheet_id={sheet_id}, view_id={view_id}")
    query_params = {
        "action": "é€šç”¨æŸ¥è¯¢è¡¨å•",
        "company": "æ‹‰ä¼¸å¤§å¸ˆ",
        "WordList": {
            "docid": docid,
            "sheet_id": sheet_id,
            "view_id": view_id
        }
    }

    try:
        async with aiohttp.ClientSession() as session:
            logger.debug(f"è¯·æ±‚ä»»åŠ¡æ•°æ®åˆ°: {API_URL}")
            logger.debug(f"è¯·æ±‚å‚æ•°: {json.dumps(query_params, ensure_ascii=False)}")

            async with session.post(
                    API_URL,
                    headers=HEADERS,
                    json=query_params,
                    timeout=60
            ) as resp:
                result = await resp.json()
                logger.debug(f"ä»»åŠ¡è¡¨å“åº”: {json.dumps(result, ensure_ascii=False)[:1000]}...")

                if result.get("success") and isinstance(result.get("data"), list):
                    logger.info(f"âœ… æˆåŠŸæŸ¥è¯¢åˆ° {len(result['data'])} æ¡ä»»åŠ¡æ•°æ®")
                    return result["data"]
                else:
                    error_msg = result.get("message", "æœªçŸ¥é”™è¯¯")
                    logger.error(f"âŒ æŸ¥è¯¢ä»»åŠ¡è¡¨å¤±è´¥: {error_msg}")
                    if "data" in result:
                        logger.debug(f"å“åº”æ•°æ®: {json.dumps(result['data'], ensure_ascii=False)[:500]}...")
                    return []
    except Exception as e:
        logger.error(f"âŒ æŸ¥è¯¢ä»»åŠ¡è¡¨å¼‚å¸¸: {str(e)}")
        return []


def parse_date_field(date_value):
    """è§£ææ—¥æœŸå­—æ®µï¼Œæ”¯æŒæ—¶é—´æˆ³å’Œæ—¥æœŸå­—ç¬¦ä¸²æ ¼å¼"""
    # ç¬¬ä¸€æ­¥ï¼šæå–æ—¥æœŸåŸå§‹å­—ç¬¦ä¸²ï¼ˆå¤„ç†å­—å…¸/åˆ—è¡¨/ç›´æ¥å­—ç¬¦ä¸²ä¸‰ç§åœºæ™¯ï¼‰
    if isinstance(date_value, dict):
        # åœºæ™¯1ï¼šå­—å…¸æ ¼å¼ï¼ˆå¦‚{"text": "2025å¹´8æœˆ29æ—¥"}ï¼‰
        date_str = date_value.get("text", "")
    elif isinstance(date_value, list) and len(date_value) > 0 and isinstance(date_value[0], dict):
        # åœºæ™¯2ï¼šåˆ—è¡¨åŒ…è£¹çš„å­—å…¸ï¼ˆå¦‚[{"text": "2025-08-29"}]ï¼‰
        date_str = date_value[0].get("text", "")
    else:
        # åœºæ™¯3ï¼šç›´æ¥å­—ç¬¦ä¸²ï¼ˆå¦‚"1756396800000"æˆ–"2025å¹´8æœˆ29æ—¥"ï¼‰
        date_str = str(date_value).strip()

    # ç¬¬äºŒæ­¥ï¼šå°è¯•è§£æä¸ºæ¯«ç§’æ—¶é—´æˆ³
    try:
        timestamp = int(date_str)
        timestamp_sec = timestamp / 1000  # æ¯«ç§’è½¬ç§’
        # UTCæ—¶é—´æˆ³è½¬æœ¬åœ°æ—¶åŒºæ—¶é—´ï¼ˆè‡ªåŠ¨é€‚é…UTC+8ï¼‰
        dt_local = datetime.fromtimestamp(timestamp_sec)
        return dt_local.strftime("%Y-%m-%d")
    except (ValueError, TypeError):
        # ç¬¬ä¸‰æ­¥ï¼šè§£æä¸ºå¸¸è§„æ—¥æœŸå­—ç¬¦ä¸²ï¼ˆæ”¯æŒå¤šç§æ ¼å¼ï¼‰
        date_formats = ["%Y-%m-%d", "%Yå¹´%mæœˆ%dæ—¥", "%Y/%m/%d"]
        for fmt in date_formats:
            try:
                dt = datetime.strptime(date_str, fmt)
                return dt.strftime("%Y-%m-%d")
            except ValueError:
                continue
        # æ— æ³•è§£ææ—¶è¿”å›åŸå§‹å­—ç¬¦ä¸²ï¼ˆä¾¿äºæ—¥å¿—æ’æŸ¥ï¼‰
        return date_str

async def process_tasks(wecom_handler: WeComTaskHandler, docid: str, sheet_id: str, view_id: str):
    """
    æ ¸å¿ƒæµç¨‹ï¼šè¯»å–ä»»åŠ¡è¡¨å¹¶åˆ›å»ºç¾¤å‘ä»»åŠ¡
    """
    # 1. ä»ä»»åŠ¡è¡¨è·å–ä»»åŠ¡æ•°æ®
    logger.info("âŒ› æ­£åœ¨æŸ¥è¯¢ä»»åŠ¡è¡¨...")
    tasks = await fetch_task_table(docid, sheet_id, view_id)
    if not tasks:
        logger.warning("âš ï¸ æœªè·å–åˆ°ä»»åŠ¡æ•°æ®ï¼Œæµç¨‹ç»ˆæ­¢")
        return

    logger.info(f"å¼€å§‹å¤„ç† {len(tasks)} æ¡ä»»åŠ¡...")

    # è·å–ä»Šå¤©çš„æ—¥æœŸå­—ç¬¦ä¸²ï¼ˆYYYY-MM-DDï¼‰
    today = datetime.now().strftime("%Y-%m-%d")
    logger.debug(f"ä»Šå¤©çš„æ—¥æœŸ: {today}")

    valid_task_count = 0


    # 2. éå†æ¯æ¡ä»»åŠ¡
    for task in tasks:
        logger.debug("=" * 80)
        logger.debug(f"ä»»åŠ¡åŸå§‹æ•°æ®: {json.dumps(task, ensure_ascii=False)[:500]}...")

        try:
            values = task.get("values", {})
            logger.debug(f"ä»»åŠ¡å€¼: {json.dumps(values, ensure_ascii=False)[:500]}...")

            # ä»»åŠ¡åç§°è¿‡æ»¤
            task_name_cell = values.get("ä»»åŠ¡å", [{}])[0]
            task_name = task_name_cell.get("text", "")
            logger.debug(f"ä»»åŠ¡åç§°: {task_name} (ç±»å‹: {type(task_name)}")

            if task_name != "é¢†å–ç¤¼å“":
                logger.debug(f"è·³è¿‡ä»»åŠ¡: åç§°ä¸åŒ¹é… ({task_name} != æµ‹è¯•ç¾¤å‘ä»»åŠ¡)")
                continue

            # å‘é€æ—¥æœŸè¿‡æ»¤ï¼šä¿®å¤å–å€¼æ ¼å¼é”™è¯¯
            send_date_raw = values.get("ä»»åŠ¡å‘é€æ—¥æœŸ", "")
            # å¤„ç†ã€Œç›´æ¥å­—ç¬¦ä¸²ã€æˆ–ã€Œåˆ—è¡¨å­—å…¸ã€ä¸¤ç§æ ¼å¼
            if isinstance(send_date_raw, list) and len(send_date_raw) > 0:
                send_date_cell = send_date_raw[0]
            else:
                send_date_cell = send_date_raw
            # è§£ææ—¥æœŸ
            send_date = parse_date_field(send_date_cell)

            logger.debug(f"å‘é€æ—¥æœŸ: {send_date} (ä»Šå¤©: {today})")

            if send_date != today:
                logger.debug(f"è·³è¿‡ä»»åŠ¡: æ—¥æœŸä¸åŒ¹é… ({send_date} != {today})")
                continue

            # æå–æ‰€éœ€å­—æ®µ
            # å¤–éƒ¨ç”¨æˆ·IDï¼ˆé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ—è¡¨ï¼‰
            external_userid_cell = values.get("externalUserid", [{}])[0]
            external_userid_str = external_userid_cell.get("text", "")
            logger.debug(f"åŸå§‹external_userid: {external_userid_str}")
            external_userid = [x.strip() for x in external_userid_str.split(",") if x.strip()]
            logger.debug(f"è§£æåexternal_userid: {external_userid}")

            # è¯æœ¯å†…å®¹
            content_cell = values.get("è¯æœ¯", [{}])[0]
            content = content_cell.get("text", "")
            logger.debug(f"è¯æœ¯å†…å®¹: {content[:50]}...")

            # ä»»åŠ¡å›¾ç‰‡ï¼šä»å­—å…¸åˆ—è¡¨ä¸­æå–image_urlï¼ˆæ™ºèƒ½è¡¨å›¾ç‰‡å­—æ®µçš„æ ‡å‡†æ ¼å¼ï¼‰
            task_images = values.get("ä»»åŠ¡å›¾ç‰‡", [])
            image_urls = []
            for img_info in task_images:
                if isinstance(img_info, dict):
                    img_url = img_info.get("image_url")
                    if img_url and img_url.startswith(("http://", "https://")):
                        image_urls.append(img_url)
            logger.debug(f"è§£æåˆ°å›¾ç‰‡URL: {image_urls}")

            # å‘é€äººID
            sender_list = values.get("å¾…å‘é€", [])
            logger.debug(f"åŸå§‹å¾…å‘é€æ•°æ®: {sender_list}")

            sender_ids = []
            for member in sender_list:
                if "user_id" in member:
                    sender_ids.append(member["user_id"])
                    logger.debug(f"ä»æˆå‘˜å­—æ®µè·å–user_id: {member['user_id']}")
                elif "text" in member:
                    # å¦‚æœå­—æ®µæ˜¯æ–‡æœ¬ç±»å‹è€Œä¸æ˜¯æˆå‘˜ç±»å‹
                    user_ids = [id.strip() for id in member["text"].split(",")]
                    sender_ids.extend(user_ids)
                    logger.debug(f"ä»æ–‡æœ¬å­—æ®µè§£æuser_id: {user_ids}")

            # å¦‚æœsender_idsä¸ºç©ºåˆ™ä½¿ç”¨ç©ºåˆ—è¡¨
            sender_ids = sender_ids if sender_ids else []
            logger.debug(f"å‘é€äººIDåˆ—è¡¨: {sender_ids}")

            valid_task_count += 1
            logger.info(f"ğŸ¯ æ‰¾åˆ°åŒ¹é…ä»»åŠ¡: {task_name} (å‘é€æ—¥æœŸ: {send_date})")

        except Exception as e:
            logger.error(f"âš ï¸ ä»»åŠ¡æ•°æ®å¤„ç†å¼‚å¸¸: {str(e)}")
            import traceback
            logger.debug(traceback.format_exc())
            continue

        # 3. ä¸ºæ¯ä¸ªå‘é€äººåˆ›å»ºç¾¤å‘ä»»åŠ¡
        if not sender_ids:
            logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°å‘é€äººIDï¼Œè·³è¿‡æ­¤ä»»åŠ¡")
            continue

        for sender in sender_ids:
            if external_userid and content and sender:
                logger.info(f"ğŸ“¨ å¼€å§‹å¤„ç†ä»»åŠ¡: {task_name} (å‘é€äºº: {sender})")

                # åˆ›å»ºç¾¤å‘ä»»åŠ¡
                logger.info(f"ğŸ•’ å‡†å¤‡å‘é€æ¶ˆæ¯ç»™ {len(external_userid)} ä½å®¢æˆ·...")
                result = await wecom_handler.create_mass_task(
                    external_userid=external_userid,
                    sender=sender,
                    content=content,
                    task_name=task_name,
                    image_urls=image_urls
                )

                # å¤„ç†ç»“æœ
                if result["success"]:
                    logger.info(f"âœ… ä»»åŠ¡å®Œæˆ: {task_name} (msgid: {result.get('msgid')})")
                else:
                    logger.error(f"âŒ ä»»åŠ¡å¤±è´¥: {task_name} (é”™è¯¯: {result.get('error')})")
            else:
                missing = []
                if not external_userid: missing.append("external_userid")
                if not content: missing.append("content")
                if not sender: missing.append("sender")
                logger.warning(f"âš ï¸ ç¼ºå°‘å¿…è¦å­—æ®µ: {', '.join(missing)}")

    logger.info(f"å¤„ç†å®Œæˆ: å…±å¤„ç† {valid_task_count} ä¸ªæœ‰æ•ˆä»»åŠ¡")
    if valid_task_count == 0:
        logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ä»»åŠ¡")


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("===== ğŸš€ ä¼å¾®ä»»åŠ¡è¡¨ç¾¤å‘æµç¨‹å¼€å§‹ =====")

    # åˆå§‹åŒ–ä¼å¾®å¤„ç†å™¨
    wecom_handler = WeComTaskHandler(CORPID, CORPSECRET)

    try:
        # é…ç½®ä»»åŠ¡è¡¨å‚æ•°
        docid = "dcPbCgiFT361NMXCjtOXHJRssdGcQcFBNmx-ej23sFFCjZJO1PmrZOGHDn_4dRUnUw1Nt-SD5-3fxIhNB42H1Gbw"
        sheet_id = "tyTqJV"
        view_id = "v5MarV"

        logger.info(f"ä»»åŠ¡è¡¨é…ç½®: docid={docid[:10]}..., sheet_id={sheet_id}, view_id={view_id}")

        # æ‰§è¡Œæ ¸å¿ƒæµç¨‹
        await process_tasks(wecom_handler, docid, sheet_id, view_id)

    except Exception as e:
        logger.error(f"âŒ æµç¨‹æ‰§è¡Œå¼‚å¸¸: {str(e)}")
        import traceback
        logger.debug(traceback.format_exc())
    finally:
        # å…³é—­ä¼šè¯
        logger.info("æ­£åœ¨æ¸…ç†èµ„æº...")
        await wecom_handler.close()
        logger.info("===== ğŸ æµç¨‹æ‰§è¡Œç»“æŸ =====")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except Exception as e:
        logger.error(f"ä¸»ç¨‹åºå¼‚å¸¸: {str(e)}")
        import traceback

        logger.error(traceback.format_exc())